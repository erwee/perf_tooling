{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install pandas matplotlib scipy numpy seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas\n",
    "import warnings\n",
    "import requests\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import pprint\n",
    "import seaborn\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "\n",
    "sys.path.insert(0, \"../src\")\n",
    "from perf_tools.analysis import make_differential_frame, get_data, get_summary_statistics\n",
    "from perf_tools.analysis import check_are_close, make_latency_plot, plot_latency_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YCSBLikeWorkload:\n",
    "    def __init__(self, workdir, patch_id, variant, execution, task_name):\n",
    "        self.workdir = workdir\n",
    "        self.patch_id = patch_id\n",
    "        self.variant = variant\n",
    "        self.execution = execution\n",
    "        self.task_name = task_name\n",
    "        self.load_data = None\n",
    "        self.readonly_data = None\n",
    "        self.updateonly_data = None\n",
    "        self.evensplit_read_data = None\n",
    "        self.evensplit_write_data = None\n",
    "        self.readheavy_read_data = None\n",
    "        self.readheavy_write_data = None\n",
    "        self.sharded = \"shard\" in variant\n",
    "        Path(self.plots_path()).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def json_path(self, metric):\n",
    "        return os.path.join(self.workdir, self.patch_id, self.variant,\n",
    "            self.task_name, str(self.execution), metric + \".json\")\n",
    "    def plots_path(self):\n",
    "        return os.path.join(self.workdir, \"plots\", \"sharded\" if self.sharded else \"replset\")\n",
    "        \n",
    "    def get_load_data(self):\n",
    "        if self.load_data is None:\n",
    "            self.load_data = get_data(self.json_path(\"YCSBLike.load.inserts\"))\n",
    "        return self.load_data\n",
    "    def get_100read_data(self):\n",
    "        if self.readonly_data is None:\n",
    "            self.readonly_data = get_data(self.json_path(\"YCSBLike.100read.reads\"))\n",
    "        return self.readonly_data\n",
    "    def get_100update_data(self):\n",
    "        if self.updateonly_data is None:\n",
    "            self.updateonly_data = get_data(self.json_path(\"YCSBLike.100update.writes\"))\n",
    "        return self.updateonly_data\n",
    "    def get_50read50update_data(self):\n",
    "        if self.evensplit_read_data is None:\n",
    "            self.evensplit_read_data = get_data(self.json_path(\"YCSBLike.50read50update.reads\"))\n",
    "        if self.evensplit_write_data is None:\n",
    "            self.evensplit_write_data = get_data(self.json_path(\"YCSBLike.50read50update.writes\"))\n",
    "        return self.evensplit_read_data, self.evensplit_write_data\n",
    "    def get_95read5update_data(self):\n",
    "        if self.readheavy_read_data is None:\n",
    "            self.readheavy_read_data = get_data(self.json_path(\"YCSBLike.95read5update.reads\"))\n",
    "        if self.readheavy_write_data is None:\n",
    "            self.readheavy_write_data = get_data(self.json_path(\"YCSBLike.95read5update.writes\"))\n",
    "        return self.readheavy_read_data, self.readheavy_write_data\n",
    "\n",
    "    def _plot_line_or_scatter(self, df, x, y, line=False, start=None, end=None, **kwargs):\n",
    "        if line:\n",
    "            return df[start:end].plot(x=x, y=y, figsize=(20,20), **kwargs)\n",
    "        return df[start:end].plot.scatter(x=x, y=y, figsize=(20,20), **kwargs)\n",
    "\n",
    "    def plot_load_data(self, x, y, line=False, start=None, end=None, **kwargs):\n",
    "        title=f\"{self.variant}-{self.task_name} load phase insert {y}\"\n",
    "        return self._plot_line_or_scatter(self.get_load_data().diff_data, x, y, line, start, end, title=title, **kwargs)\n",
    "    def plot_100read_data(self, x, y, line=False, start=None, end=None, **kwargs):\n",
    "        title=f\"{self.variant}-{self.task_name} 100read read {y}\"\n",
    "        return self._plot_line_or_scatter(self.get_100read_data().diff_data, x, y, line, start, end, title=title, **kwargs)\n",
    "    def plot_100update_data(self, x, y, line=False, start=None, end=None, **kwargs):\n",
    "        title=f\"{self.variant}-{self.task_name} 100update update {y}\"\n",
    "        return self._plot_line_or_scatter(self.get_100update_data().diff_data, x, y, line, start, end, title=title, **kwargs)\n",
    "    def plot_95read5update_read_data(self, x, y, line=False, start=None, end=None, **kwargs):\n",
    "        title=f\"{self.variant}-{self.task_name} 95read5update read {y}\"\n",
    "        dfr, dfw = self.get_95read5update_data()\n",
    "        return self._plot_line_or_scatter(dfr.diff_data, x, y, line, start, end, title=title, **kwargs)\n",
    "    def plot_95read5update_write_data(self, x, y, line=False, start=None, end=None, **kwargs):\n",
    "        title=f\"{self.variant}-{self.task_name} 95read5update update {y}\"\n",
    "        dfr, dfw = self.get_95read5update_data()\n",
    "        return self._plot_line_or_scatter(dfw.diff_data, x, y, line, start, end, title=title, **kwargs)\n",
    "    def plot_50read50update_read_data(self, x, y, line=False, start=None, end=None, **kwargs):\n",
    "        title=f\"{self.variant}-{self.task_name} 50read50update read {y}\"\n",
    "        dfr, dfw = self.get_50read50update_data()\n",
    "        return self._plot_line_or_scatter(dfr.diff_data, x, y, line, start, end, title=title, **kwargs)\n",
    "    def plot_50read50update_write_data(self, x, y, line=False, start=None, end=None, **kwargs):\n",
    "        title=f\"{self.variant}-{self.task_name} 50read50update update {y}\"\n",
    "        dfr, dfw = self.get_50read50update_data()\n",
    "        return self._plot_line_or_scatter(dfw.diff_data, x, y, line, start, end, title=title, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(wld, axes, filename):\n",
    "    axes.figure.savefig(os.path.join(wld.plots_path(), filename), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIANTS = {\"replset\": \"linux-3-node-replSet-qebench\", \"sharded\": \"linux-shard-lite-qebench\"}\n",
    "WORKDIR=\"../datasets/genny/ycsblike\"\n",
    "\n",
    "patch_id = \"63370d281e2d174e799c1141\"\n",
    "sharded_patch_id = \"634404703066152024a287dc\"\n",
    "exec_idx=0\n",
    "replset_executions = {\n",
    "    \"genny_qebench_unencrypted\": [0,1,2,3,4],\n",
    "    \"genny_qebench_fle_1enc\": [0,1,2,3,4],\n",
    "    \"genny_qebench_fle_5enc\": [0,1,2,3,4],\n",
    "    \"genny_qebench_qe_1enc_cf16\": [0,1,2,3,4],\n",
    "    \"genny_qebench_qe_1enc_cf32\": [0,1,2,3,4],\n",
    "    \"genny_qebench_qe_1enc_cfdefault\": [0,1,2,3,4],\n",
    "    \"genny_qebench_qe_5enc_cf16\": [0,1,2,3,4],\n",
    "    \"genny_qebench_qe_5enc_cf32\": [0,1,2,3,4],\n",
    "    \"genny_qebench_qe_5enc_cfdefault\": [0,1,2,3,4],\n",
    "}\n",
    "sharded_executions = {\n",
    "    \"genny_qebench_unencrypted\": [0,1,2,3,4],\n",
    "    \"genny_qebench_fle_1enc\": [0,1,2,3,4],\n",
    "    \"genny_qebench_fle_5enc\": [0,1,3,5,6],\n",
    "    \"genny_qebench_qe_1enc_cf16\": [0,1,2,3,4],\n",
    "    \"genny_qebench_qe_1enc_cf32\": [0,1,2,3,4],\n",
    "    \"genny_qebench_qe_1enc_cfdefault\": [1,2,3,4,5],\n",
    "    \"genny_qebench_qe_5enc_cf16\": [0,1,2,3,4],\n",
    "    \"genny_qebench_qe_5enc_cf32\": [0,1,3,4,5],\n",
    "    \"genny_qebench_qe_5enc_cfdefault\": [0,1,2,3,4],\n",
    "}\n",
    "replset_workloads = {\n",
    "    task: YCSBLikeWorkload(WORKDIR, patch_id, VARIANTS[\"replset\"], str(replset_executions[task][exec_idx]), task)\n",
    "    for task in replset_executions.keys()\n",
    "}\n",
    "sharded_workloads = {\n",
    "    task: YCSBLikeWorkload(WORKDIR, sharded_patch_id, VARIANTS[\"sharded\"], str(sharded_executions[task][exec_idx]), task)\n",
    "    for task in sharded_executions.keys()\n",
    "}\n",
    "\n",
    "## 8-thread variation\n",
    "replset_8thread_executions = {\n",
    "    \"genny_qebench_qe_1enc_cf16\": [0],\n",
    "    \"genny_qebench_qe_1enc_cf32\": [0],\n",
    "    \"genny_qebench_qe_1enc_cfdefault\": [0],\n",
    "    \"genny_qebench_qe_5enc_cf16\": [0],\n",
    "    \"genny_qebench_qe_5enc_cf32\": [0],\n",
    "    \"genny_qebench_qe_5enc_cfdefault\": [0]\n",
    "}\n",
    "sharded_8thread_executions = {\n",
    "    \"genny_qebench_qe_1enc_cf16\": [0],\n",
    "    \"genny_qebench_qe_1enc_cf32\": [0],\n",
    "    \"genny_qebench_qe_1enc_cfdefault\": [0],\n",
    "    \"genny_qebench_qe_5enc_cf16\": [0],\n",
    "    \"genny_qebench_qe_5enc_cf32\": [0],\n",
    "    \"genny_qebench_qe_5enc_cfdefault\": [0]\n",
    "}\n",
    "replset_8thread_workloads = {\n",
    "    task: YCSBLikeWorkload(WORKDIR + \"_8threads\", \"6352e6ea61837d2bb04547c1\", \n",
    "        VARIANTS[\"replset\"], str(replset_8thread_executions[task][0]), task)\n",
    "    for task in replset_8thread_executions.keys()\n",
    "}\n",
    "sharded_8thread_workloads = {\n",
    "    task: YCSBLikeWorkload(WORKDIR + \"_8threads\", \"6352e6ea61837d2bb04547c1\", \n",
    "        VARIANTS[\"sharded\"], str(sharded_8thread_executions[task][0]), task)\n",
    "    for task in sharded_8thread_executions.keys()\n",
    "}\n",
    "\n",
    "## 60gb variation\n",
    "replset_60gb_executions = {\n",
    "    \"genny_qebench_qe_1enc_cf16\": [0],\n",
    "    \"genny_qebench_qe_1enc_cf32\": [0],\n",
    "    \"genny_qebench_qe_1enc_cfdefault\": [0],\n",
    "    \"genny_qebench_qe_5enc_cf16\": [0],\n",
    "    \"genny_qebench_qe_5enc_cf32\": [0],\n",
    "    \"genny_qebench_qe_5enc_cfdefault\": [0]\n",
    "}\n",
    "sharded_60gb_executions = {\n",
    "    \"genny_qebench_qe_1enc_cf16\": [0],\n",
    "    \"genny_qebench_qe_1enc_cf32\": [0],\n",
    "    \"genny_qebench_qe_1enc_cfdefault\": [0],\n",
    "    \"genny_qebench_qe_5enc_cf16\": [0],\n",
    "    \"genny_qebench_qe_5enc_cf32\": [0],\n",
    "    \"genny_qebench_qe_5enc_cfdefault\": [0]\n",
    "}\n",
    "replset_60gb_workloads = {\n",
    "    task: YCSBLikeWorkload(WORKDIR + \"_60gb\", \"635fe75cd1fe0752e2e05ac1\", \n",
    "        VARIANTS[\"replset\"], str(replset_60gb_executions[task][0]), task)\n",
    "    for task in replset_60gb_executions.keys()\n",
    "}\n",
    "sharded_60gb_workloads = {\n",
    "    task: YCSBLikeWorkload(WORKDIR + \"_60gb\", \"635fe75cd1fe0752e2e05ac1\", \n",
    "        VARIANTS[\"sharded\"], str(sharded_60gb_executions[task][0]), task)\n",
    "    for task in sharded_60gb_executions.keys()\n",
    "}\n",
    "\n",
    "replset_short_workloads = {\n",
    "    task: YCSBLikeWorkload(WORKDIR + \"_short\", \"636d40c25623432c2407e2a0\",\n",
    "        \"linux-1-node-replSet-qebench\", str(execution), task)\n",
    "    for task, execution in {\n",
    "        \"genny_qebench_qe_1enc_cf16\": 0,\n",
    "        \"genny_qebench_qe_1enc_cf32\": 0,\n",
    "        \"genny_qebench_qe_1enc_cfdefault\": 0,\n",
    "        \"genny_qebench_qe_5enc_cf16\": 0,\n",
    "        \"genny_qebench_qe_5enc_cf32\": 0,\n",
    "        \"genny_qebench_qe_5enc_cfdefault\": 0\n",
    "    }.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row=\"total_ops\"\n",
    "start = None\n",
    "end = None\n",
    "pp = pprint.PrettyPrinter()\n",
    "workloads = replset_short_workloads\n",
    "# workloads = replset_workloads\n",
    "# workloads = sharded_workloads\n",
    "# workloads = replset_8thread_workloads\n",
    "# workloads = replset_60gb_workloads\n",
    "# workloads = sharded_60gb_workloads\n",
    "save_plots = True\n",
    "\n",
    "def try_save_plot(wld, ax, filename):\n",
    "    if save_plots:\n",
    "        save_plot(wld, ax, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task, wld in workloads.items():\n",
    "    ax = wld.plot_load_data(row, \"pure_latency(ms)\", line=True, start=start, end=end)\n",
    "    try_save_plot(wld, ax, f\"{task}_load_latency.png\")\n",
    "\n",
    "    ax = wld.plot_load_data(\"ts\", \"throughput\", True, start, end, ylabel=\"throughput (ops/sec)\")\n",
    "    try_save_plot(wld, ax, f\"{task}_load_throughput_vs_ts.png\")\n",
    "    \n",
    "    dfs = wld.get_load_data()\n",
    "    title = f\"{wld.variant} {wld.task_name} insert stats\"\n",
    "    ax = plot_latency_stats(dfs.diff_data, row, title=title, regr=\"log\", start=start, end=end)\n",
    "    try_save_plot(wld, ax, f\"{task}_load_latency_stats.png\")\n",
    "    pp.pprint(get_summary_statistics(dfs.diff_data, dfs.fixed_data, dfs.raw_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task, wld in workloads.items():\n",
    "    ax = wld.plot_100read_data(row, \"pure_latency(ms)\", start, end)\n",
    "    try_save_plot(wld, ax, f\"{task}_100read_latency.png\")\n",
    "\n",
    "    ax = wld.plot_100read_data(\"ts\", \"throughput\", True, start, end, ylabel=\"throughput (ops/sec)\")\n",
    "    try_save_plot(wld, ax, f\"{task}_100read_throughput_vs_ts.png\")\n",
    "\n",
    "    dfs = wld.get_100read_data()\n",
    "    title = f\"{wld.variant} {wld.task_name} 100read stats\"\n",
    "    ax = plot_latency_stats(dfs.diff_data, row, title=title, regr=\"line\", start=start, end=end)\n",
    "    try_save_plot(wld, ax, f\"{task}_100read_latency_stats.png\")\n",
    "    pp.pprint(get_summary_statistics(dfs.diff_data, dfs.fixed_data, dfs.raw_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task, wld in workloads.items():\n",
    "    ax = wld.plot_95read5update_read_data(row, \"pure_latency(ms)\", start, end)\n",
    "    try_save_plot(wld, ax, f\"{task}_95read5update_read_latency.png\")\n",
    "\n",
    "    ax = wld.plot_95read5update_write_data(row, \"pure_latency(ms)\", start, end)\n",
    "    try_save_plot(wld, ax, f\"{task}_95read5update_write_latency.png\")\n",
    "\n",
    "    rdfs = wld.get_95read5update_data()[0]\n",
    "    wdfs = wld.get_95read5update_data()[1]\n",
    "    title = f\"{wld.variant} {wld.task_name} 95read5update read stats\"\n",
    "    ax = plot_latency_stats(rdfs.diff_data, row, title=title, regr=\"log\", start=start, end=end)\n",
    "    try_save_plot(wld, ax, f\"{task}_95read5update_read_latency_stats.png\")\n",
    "\n",
    "    title = f\"{wld.variant} {wld.task_name} 95read5update update stats\"\n",
    "    ax = plot_latency_stats(wdfs.diff_data, row, title=title, regr=\"line\", start=start, end=end)\n",
    "    try_save_plot(wld, ax, f\"{task}_95read5update_write_latency_stats.png\")\n",
    "\n",
    "    pp.pprint(get_summary_statistics(rdfs.diff_data, rdfs.fixed_data, rdfs.raw_data))\n",
    "    pp.pprint(get_summary_statistics(wdfs.diff_data, wdfs.fixed_data, wdfs.raw_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task, wld in workloads.items():\n",
    "    ax = wld.plot_95read5update_read_data(\"ts\", \"throughput\", True, start, end, ylabel=\"throughput (ops/sec)\")\n",
    "    try_save_plot(wld, ax, f\"{task}_95read5update_read_throughput_vs_ts.png\")\n",
    "    ax = wld.plot_95read5update_write_data(\"ts\", \"throughput\", True, start, end, ylabel=\"throughput (ops/sec)\")\n",
    "    try_save_plot(wld, ax, f\"{task}_95read5update_write_throughput_vs_ts.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task, wld in workloads.items():\n",
    "    ax = wld.plot_100update_data(row, \"pure_latency(ms)\", start, end)\n",
    "    try_save_plot(wld, ax, f\"{task}_100update_latency.png\")\n",
    "\n",
    "    ax = wld.plot_100update_data(\"ts\", \"throughput\", True, start, end, ylabel=\"throughput (ops/sec)\")\n",
    "    try_save_plot(wld, ax, f\"{task}_100update_throughput_vs_ts.png\")\n",
    "\n",
    "    dfs = wld.get_100update_data()\n",
    "    title = f\"{wld.variant} {wld.task_name} 100update update stats\"\n",
    "    ax = plot_latency_stats(dfs.diff_data, row, title=title, regr=\"line\", start=start, end=end)\n",
    "    try_save_plot(wld, ax, f\"{task}_100update_latency_stats.png\")\n",
    "\n",
    "    pp.pprint(get_summary_statistics(dfs.diff_data, dfs.fixed_data, dfs.raw_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task, wld in workloads.items():\n",
    "    ax = wld.plot_50read50update_read_data(row, \"pure_latency(ms)\", start, end)\n",
    "    try_save_plot(wld, ax, f\"{task}_50read50update_read_latency.png\")\n",
    "\n",
    "    ax = wld.plot_50read50update_write_data(row, \"pure_latency(ms)\", start, end)\n",
    "    try_save_plot(wld, ax, f\"{task}_50read50update_write_latency.png\")\n",
    "\n",
    "    rdfs = wld.get_50read50update_data()[0]\n",
    "    wdfs = wld.get_50read50update_data()[1]\n",
    "    title = f\"{wld.variant} {wld.task_name} 50read50update read stats\"\n",
    "    ax = plot_latency_stats(rdfs.diff_data, row, title=title, regr=\"line\", start=start, end=end)\n",
    "    try_save_plot(wld, ax, f\"{task}_50read50update_read_latency_stats.png\")\n",
    "\n",
    "    title = f\"{wld.variant} {wld.task_name} 50read50update update stats\"\n",
    "    ax = plot_latency_stats(wdfs.diff_data, row, title=title, regr=\"line\", start=start, end=end)\n",
    "    try_save_plot(wld, ax, f\"{task}_50read50update_write_latency_stats.png\")\n",
    "\n",
    "    pp.pprint(get_summary_statistics(rdfs.diff_data, rdfs.fixed_data, rdfs.raw_data))\n",
    "    pp.pprint(get_summary_statistics(wdfs.diff_data, wdfs.fixed_data, wdfs.raw_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task, wld in workloads.items():\n",
    "    ax = wld.plot_50read50update_read_data(\"ts\", \"throughput\", True, start, end, ylabel=\"throughput (ops/sec)\")\n",
    "    try_save_plot(wld, ax, f\"{task}_50read50update_read_throughput_vs_ts.png\")\n",
    "    ax = wld.plot_50read50update_write_data(\"ts\", \"throughput\", True, start, end, ylabel=\"throughput (ops/sec)\")\n",
    "    try_save_plot(wld, ax, f\"{task}_50read50update_write_throughput_vs_ts.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('venv': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a9de337d49c809f126ef412fa5b70dd3b8eac743dbb23eeffda322bc3293c07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
